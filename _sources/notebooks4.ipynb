{"cells":[{"cell_type":"markdown","source":["# Tugas 2 (Membuat Pipelines beserta deskripsi)"],"metadata":{"id":"YKLAx40X3ig3"}},{"cell_type":"markdown","source":["## Pertama kita melakukan proses untuk mengambil data dari berbagai database, disini kita menggunakan dataset iris yang nantinya diambil 4 fitur dan 1 targetnya yaitu sepallength, sepalwidth, petallength, petalwidth, dan class. "],"metadata":{"id":"12V6ad-23xCE"}},{"cell_type":"markdown","source":["### SQL Server (petalwidth,class)"],"metadata":{"id":"zb0tgROA5Cwz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ooelEWuK2cvQ","outputId":"8280ee62-bb32-4b04-e24f-804325759701"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Dio\\AppData\\Local\\Temp/ipykernel_18780/1868463945.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n","  pwcs = pd.read_sql(query, cnxn)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>petalwidth</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   petalwidth        class\n","0         0.2  Iris-setosa\n","1         0.2  Iris-setosa\n","2         0.2  Iris-setosa\n","3         0.2  Iris-setosa\n","4         0.2  Iris-setosa"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# connect to SQL Server and read data from table iris.arff\n","import pyodbc\n","import pandas as pd\n","\n","server = 'LAPTOP-H7SNH2OP\\SQLEXPRESS' \n","database = 'prosainsdata200411100066' \n","\n","cnxn = pyodbc.connect(r'Driver=ODBC Driver 17 for SQL Server;Server=LAPTOP-H7SNH2OP\\SQLEXPRESS;Database=prosainsdata(200411100066);Trusted_Connection=yes;')  \n","cursor = cnxn.cursor()\n","\n","# select 26 rows from SQL table to insert in dataframe.\n","query = \"SELECT petalwidth,class FROM [prosainsdata(200411100066)].[dbo].[iris.arff]\"\n","pwcs = pd.read_sql(query, cnxn)\n","pwcs = pd.DataFrame(pwcs, columns=['petalwidth','class'])\n","pwcs.head()"]},{"cell_type":"markdown","source":["### Postgres (sepallength)"],"metadata":{"id":"Xsdzvqf881X6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WyzOPiY2cvX","outputId":"9fe1088a-d746-44d8-dfdd-068cbf4e1525"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepallength</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepallength\n","0          5.1\n","1          4.9\n","2          4.7\n","3          4.6\n","4          5.0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# connect to PostgreSQL and read data from table iris.arff\n","import psycopg2\n","\n","conn = psycopg2.connect(\n","    database=\"prosainsdata(200411100066)\",\n","    user=\"postgres\",\n","    password=\"1234\",\n","    host=\"localhost\",\n","    port=\"5432\"\n",")\n","\n","cur = conn.cursor()\n","\n","cur.execute(\"SELECT sepallength FROM iris_arff\")\n","\n","rows = cur.fetchall()\n","\n","sl = pd.DataFrame(rows, columns=['sepallength'])\n","sl.head()"]},{"cell_type":"markdown","source":["### ElephantSQL (sepalwidth)"],"metadata":{"id":"SwVf5FOP88Yc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI-thXJK2cvY","outputId":"2de3d542-967d-4486-8aed-17389e2cb9b1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepalwidth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  sepalwidth\n","0        3.5\n","1          3\n","2        3.2\n","3        3.1\n","4        3.6"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# connect elephantsql and read data from table iris.arff\n","import psycopg2\n","\n","conn = psycopg2.connect(\n","    database=\"mpbecome\",\n","    user=\"mpbecome\",\n","    password=\"qJrkkEHbBQhzOh5rwG0vL_T-6qVzLrJE\",\n","    host=\"satao.db.elephantsql.com\",\n","    port=\"5432\"\n",")\n","\n","cur = conn.cursor()\n","\n","cur.execute(\"SELECT sepalwidth FROM iris\")\n","\n","rows = cur.fetchall()\n","\n","sw = pd.DataFrame(rows, columns=['sepalwidth'])\n","sw.head()"]},{"cell_type":"markdown","source":["### XAMPP (petallength)"],"metadata":{"id":"H7GRUJfi9Sj3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCyyU3F22cvZ","outputId":"d5dfd60d-722f-4b6b-88de-79a19d020116"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>petallength</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  petallength\n","0         1.4\n","1         1.4\n","2         1.3\n","3         1.5\n","4         1.4"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# connect to the localhost xaamp server\n","import mysql.connector\n","mydb = mysql.connector.connect(\n","    host='localhost',\n","    user='root',\n","    password='',\n","    database='prosainsdata(200411100066)'\n",")\n","mycursor = mydb.cursor()\n","\n","# select 26 rows from SQL table to insert in dataframe.\n","mycursor.execute(\"SELECT petallength FROM iris_arff\")\n","myresult = mycursor.fetchall()\n","\n","pl = pd.DataFrame(myresult, columns=['petallength'])\n","pl.head()"]},{"cell_type":"markdown","source":["### Setelah mengambil fitur dan target dari berbagai sumber maka langkah selanjutnya yaitu menggabungkan fitur dan target kedalam satu kolom"],"metadata":{"id":"quTRFYL69l4I"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_D8g3Fg2cva","outputId":"29bba247-c025-4a13-b4f3-ffb0c05ab00a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepallength</th>\n","      <th>sepalwidth</th>\n","      <th>petallength</th>\n","      <th>petalwidth</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepallength sepalwidth petallength  petalwidth        class\n","0          5.1        3.5         1.4         0.2  Iris-setosa\n","1          4.9          3         1.4         0.2  Iris-setosa\n","2          4.7        3.2         1.3         0.2  Iris-setosa\n","3          4.6        3.1         1.5         0.2  Iris-setosa\n","4          5.0        3.6         1.4         0.2  Iris-setosa"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["iris_df = pd.concat([sl, sw, pl, pwcs], axis=1)\n","iris_df.head()"]},{"cell_type":"markdown","source":["### Selanjutnya kita menyimpan per fitur untuk proses upload kedalam Orchest"],"metadata":{"id":"f8dO5thx--MU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxhCxVpi2cvb"},"outputs":[],"source":["# convert to csv\n","pl.to_csv('pl_iris.csv', index=False)\n","sl.to_csv('sl_iris.csv', index=False)\n","sw.to_csv('sw_iris.csv', index=False)\n","pwcs.to_csv('pwcs_iris.csv', index=False)"]},{"cell_type":"markdown","source":["## Selanjutnya, kita masuk kedalam Orchest untuk melakukan proses membuat pipeline"],"metadata":{"id":"H4zSGKv1AAiz"}},{"cell_type":"markdown","source":["### import csv ke Orchest"],"metadata":{"id":"V4Jylx4XBLQO"}},{"cell_type":"markdown","source":["### get_data.py"],"metadata":{"id":"1lfS_i_ZA9Sa"}},{"cell_type":"code","source":["import orchest\n","import pandas as pd\n","# from sklearn import datasets\n","\n","# Explicitly cache the data in the \"/data\" directory since the\n","# kernel is running in a Docker container, which are stateless.\n","# The \"/data\" directory is a special directory managed by Orchest\n","# to allow data to be persisted and shared across pipelines and\n","# even projects.\n","# print(\"Dowloading California housing data...\")\n","# data = datasets.fetch_california_housing(data_home=\"/data\")\n","pl=pd.read_csv('dataset/pl_iris.csv')\n","sl=pd.read_csv('dataset/sl_iris.csv')\n","sw=pd.read_csv('dataset/sw_iris.csv')\n","pwcs=pd.read_csv('dataset/pwcs_iris.csv')\n","\n","data = pd.concat([sl, sw, pl, pwcs], axis=1)\n","\n","# Convert the data into a DataFrame.\n","# df_data = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n","# df_target = pd.DataFrame(data[\"target\"], columns=[\"MedHouseVal\"])\n","# fitur\n","df_data = data.iloc[:, :-1]\n","# target\n","df_target = data.iloc[:, 4]\n","\n","# Output the housing data so the next steps can retrieve it.\n","print(\"Outputting converted \")\n","orchest.output((df_data, df_target), name=\"data\")\n","print(\"Success!\")\n","\n","data.head()"],"metadata":{"id":"WQBoyl-2BCSI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### split_data"],"metadata":{"id":"NbJAxV5ACcJZ"}},{"cell_type":"code","source":["import orchest\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","# from sklearn.preprocessing import MinMaxScaler\n","data = orchest.get_inputs() \n","X, y = data[\"data\"]\n","# scaler = MinMaxScaler()\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n","# X_train = scaler.fit_transform(X_train)\n","# X_test = scaler.transform(X_test)\n","orchest.output((X_train, y_train, X_test, y_test), name=\"training_data\")"],"metadata":{"id":"wR1VeHYxCbyr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### knn"],"metadata":{"id":"XnyflYImCjSz"}},{"cell_type":"code","source":["import numpy as np\n","import orchest\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import mean_squared_error\n","# Retrieve the data from the previous step.\n","data = orchest.get_inputs()\n","X_train, y_train, X_test, y_test = data[\"training_data\"]\n","\n","model = KNeighborsClassifier(n_neighbors = 15)\n","model.fit(X_train, y_train)\n","from sklearn.metrics import accuracy_score\n","y_pred = model.predict(X_test)\n","test_accracy = accuracy_score(y_test, y_pred)\n","orchest.output(test_accracy, name=\"KNeighborsClassifier\")"],"metadata":{"id":"RObGd_toClkb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### naive_bayes"],"metadata":{"id":"yBSudZuQC2SK"}},{"cell_type":"code","source":["import numpy as np\n","import orchest\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import mean_squared_error\n","# Retrieve the data from the previous step.\n","data = orchest.get_inputs()\n","X_train, y_train, X_test, y_test = data[\"training_data\"]\n","\n","model = GaussianNB()\n","model.fit(X_train, y_train)\n","from sklearn.metrics import accuracy_score\n","y_pred = model.predict(X_test)\n","test_accracy = accuracy_score(y_test, y_pred)\n","orchest.output(test_accracy, name=\"GaussianNB\")"],"metadata":{"id":"4laSg-xDC89p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### logistigreq"],"metadata":{"id":"AeTpSRv1DBf8"}},{"cell_type":"code","source":["import numpy as np\n","import orchest\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import mean_squared_error\n","# Retrieve the data from the previous step.\n","data = orchest.get_inputs()\n","X_train, y_train, X_test, y_test = data[\"training_data\"]\n","\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","from sklearn.metrics import accuracy_score\n","y_pred = model.predict(X_test)\n","test_accracy = accuracy_score(y_test, y_pred)\n","orchest.output(test_accracy, name=\"logistic-regression-accuracy\")"],"metadata":{"id":"IYYzhk7vDIlH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### collect-result"],"metadata":{"id":"oqfev3sSDPx1"}},{"cell_type":"code","source":["import orchest\n","data = orchest.get_inputs()\n","for name, value in data.items():\n","    if name != \"unnamed\":\n","        print(f\"\\n{name:30} {value}\")"],"metadata":{"id":"pDqTxptUDV3p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setelah melakukan proses diatas maka langkah yang terakhir adalah dengan mendapat hasil dari perhitungan dalam pipeline, didalam pipeline saya terdapat 3 model yang digunakan untuk klasifikasi"],"metadata":{"id":"Ez8-v8qrDgvR"}}],"metadata":{"kernelspec":{"display_name":"Python 3.9.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"800d7d72e1656d62149aad0109272b9fc1820f1f4424e796988e696c3c5dab3d"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}